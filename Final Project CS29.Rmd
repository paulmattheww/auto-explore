---
title: "<b>Towards Automating Exploratory Data Analysis</b>"
author: "Paul M Washburn"
date: "<small>May 6, 2019</small>"
output: revealjs::revealjs_presentation#html_document #ioslides_presentation #slidy_presentation #beamer_presentation #revealjs::revealjs_presentation
theme: solarized
center: true
fig_width: 10
fig_height: 4
fig_caption: true
widescreen: true
# navigation: slide
transition: rotate
background_transition: concave
# width: 1500
# height: 1200
autosize: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# <b>`auto_explore`</b> <small>Machine learning practitioners need first to identify signal in their datasets before building models.<br><br>Iteration cycle time *matters* in the development of machine learning solutions.  This work is a first attempt at accelerating this cycle time for a range of dataset types.<br><br>It is assumed the user is inside a Jupyter Notebook REPL environment.</small> {data-background=#AAE6E6}


## Towards Automated Exploration

The primary goal of [`auto-explore`](https://github.com/paulmattheww/auto-explore) is to to establish a codebase that reduces the effort to produce a reasonable first-pass exploratory data analysis for a variety of dataset types.

This Python library is a first attempt at automating the process of exploratory data analysis -- at least as far as computation and visualization is concerned.  

Critical thinking is *not* included.

## Potential Benefits of Semi-automated EDA

- Faster time to **insights & modeling**
- Shorter exploratory data analysis turnaround
- Reliable processes that are **vetted & improved** over time
- No need to re-configure old code to new situations
- Supplies a base for more in-depth analysis

## Inspirational & Instrumental Works

This work necessarily relied upon many excellent open source Python libraries.  Some of the inspirations and instrumental tools have been:

- <small>[`pandas-profiling`](https://github.com/pandas-profiling/pandas-profiling):  This work was ultimately not used in this library due to neglect of the project.</small>
- <small>[`featexp`](https://github.com/abhayspawar/featexp):  A great tool for visualizing univariate analyses of a target; useful pre-ML.  This library was integrated into this one for experimentation on extending the work, and is used in producing univariate plots and feature selections.</small>
- <small>[`matplotlib`](https://matplotlib.org/):  The bare-bones go-to viz package for Python.  This package was relied upon heavily to produce this library.</small>
- <small>[`seaborn`](https://seaborn.pydata.org/):  Abstracts away from `matplotlib` by performing statistical analysis alongside plot generation.  This package is also relied upon heavily.</small>
- <small>[`pandas`](https://pandas.pydata.org/):  The go-to data wrangling tool for Python.  `pandas`' `pd.DataFrame` object as well as many of the `tseries` capabilities are leveraged.</small>
- <small>[`sklearn`](https://scikit-learn.org/):  An indispensable machine learning library that every data scientist should be proficient in using.  All the functionality desired from this package has not yet been integrated into `auto-explore`, but there are plans to leverage this package more in the future.</small>

# <b>Overview</b> <small>The goal was to simply specify a dataset and a few attributes and get analytic visualizations for free.<br><br>Much of the functionality of this library is to generate visualizations that are useful in understanding data.  However there is a great deal of analytical functionality included as well, including some lightweight machine learning.</small> {data-background=#F2D478}

## Linear Regression Analysis

![lmplot](/Users/pmw/Desktop/templates/auto-explore/img/lmplot.png)

## Text Analysis

![tsne](/Users/pmw/Desktop/templates/auto-explore/img/tsne cluster.png){width=850px}

## Time Series Analysis

![plot_tseries_over_group_with_histograms](/Users/pmw/Desktop/templates/auto-explore/img/tseries.png)

## Correlation Analysis

![correlation_heatmap](/Users/pmw/Desktop/templates/auto-explore/img/heatmap.png){width=800px}

## Correlation Analysis

![scatterplotmatrix](/Users/pmw/Desktop/templates/auto-explore/img/scatterplot matrix.png){width=675px}


## Categorical Analysis

![target_distribution_over_binary_groups](/Users/pmw/Desktop/templates/auto-explore/img/boxen.png){width=800px}


## Clustering Analysis

![cluster_and_plot_pca1](/Users/pmw/Desktop/templates/auto-explore/img/kmeans.png){width=800px}

## Clustering Analysis

![cluster_and_plot_pca2](/Users/pmw/Desktop/templates/auto-explore/img/silhouette.png){width=800px}

## Clustering Analysis

![elbow](/Users/pmw/Desktop/templates/auto-explore/img/elbow.png){width=800px}

## Helper Functions

```python
In [10]: from auto_explore.datetime import make_calendars
In [11]: year_list = np.arange(2011, 2020)
In [12]: cal_df = make_calendars(year_list, drop_index=False)
In [13]: cal_df.head()                                                                                                          
Out[13]: 
              month  year    weekday  is_weekday  is_holiday  is_holiday_week
DATE                                                                         
2011-01-01  January  2011   Saturday           0           0                0
2011-01-02  January  2011     Sunday           0           0                0
2011-01-03  January  2011     Monday           1           0                0
2011-01-04  January  2011    Tuesday           1           0                0
2011-01-05  January  2011  Wednesday           1           0                0
```

## Helper Functions

```python
In [10]: from auto_explore.apis import fetch_fred_data
In [11]: series_list = ['SP500', 'NASDAQCOM', 'DJIA', 'RU2000PR'] # cboe energy sector etf volatility
In [12]: econ_df = fetch_fred_data(series_list)
In [13]: econ_df.head()
Out[13]: 
              SP500  NASDAQCOM      DJIA  RU2000PR
DATE                                              
2011-01-03  1271.87    2691.52  11670.75   1984.61
2011-01-04  1270.20    2681.25  11691.18   1952.99
2011-01-05  1276.56    2702.20  11722.89   1976.01
2011-01-06  1273.85    2709.89  11697.31   1966.88
2011-01-07  1271.50    2703.17  11674.76   1957.96            0
```


# <b>Functionality & Use</b> <small>Using the `AutopilotExploratoryAnalysis` object will make many methods available on your data with minimal set up.<br><br>However each module in this library can be used separately without ever instantiating this object.<br><br>Streamlining functionality into this object is still in alpha stages and is by no means perfect.  True automation is a ways away.</small> {data-background=#B5F55E}



## `auto_explore.eda`

This part of the library was designed to be an interface to automatic exploration.

Simply specify a `DataFrame` and a list for each of its binary, categorical, numerical and text columns.  If applicable, set the `target_col` as a list with one element (string).  

```python
from auto_explore.eda import AutopilotExploratoryAnalysis

args = (df, bin_cols, cat_cols, num_cols, text_cols)
kwargs = dict(target_col=target_col)
ax = AutopilotExploratoryAnalysis(*args, **kwargs)
```

This object makes available 17 methods for use on the `df` supplied as an arg.  Check out the most recent code on [Github](https://github.com/paulmattheww/auto-explore/blob/master/src/auto_explore/eda.py).

## Other Modules 

The actual functionality of the `AutopilotExploratoryAnalysis` object has been abstracted away and modularized into various files within the `auto_explore` package.  This allows for re-use of the code even if the automated option is not taken.  

- <small>`auto_explore.viz` - Contains all the visualization functions useful in EDA</small>
- <small>`auto_explore.featexp` - A copy [`featexp`](https://github.com/abhayspawar/featexp) code with custom changes; possible pull request in the future</small>
- <small>`auto_explore.apis` - Code that fetches data and machine learning models from sources</small>
- <small>`auto_explore.notebooks` - Formatting code for inside a Jupyter Notebook REPL environment</small>
- <small>`auto_explore.stats` - Currently only houses `best_theoretical_distribution`</small>
- <small>`auto_explore.datetime` - Houses code pertaining to time-series feature generation</small>
- <small>`auto_explore.diligence` - Houses code that performs sanity checks of various sorts</small>




# <b>Future Work</b> <small>The goal for this library is to automate as much of the EDA process as possible for as wide a range of dataset types as possible.<br><br>The library is not quite there yet.<br><br>Until then efforts will be made to abstract and integrate into this code base as many EDA tasks as possible, and eventually have a `full_suite_report` mechanism.</small> {data-background=#CAF4BB}


# <b>Questions?</b> <small>*"The part that is stable we shall predict. The part that is unstable we shall control"*<br><br>John von Neumann</small> {data-background=#40f9b6}

